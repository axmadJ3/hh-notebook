{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axmadJ3/hh-notebook/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22hh_vacancy_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FW55AeCaB-H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/HH_Vacancy/"
      ],
      "metadata": {
        "id": "4kv7kH_iCkeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4 urllib3 openpyxl tqdm selenium webdriver-manager"
      ],
      "metadata": {
        "id": "wfYA9oCXEKLa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачиваем Google Chrome 115\n",
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "\n",
        "# Устанавливаем скачанный .deb пакет\n",
        "!dpkg -i google-chrome-stable_current_amd64.deb\n",
        "\n",
        "!google-chrome-stable --version\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WBKUdarjHSm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачиваем ChromeDriver для соответствующей версии Google Chrome\n",
        "!wget https://storage.googleapis.com/chrome-for-testing-public/131.0.6778.85/linux64/chromedriver-linux64.zip\n",
        "\n",
        "# Разархивируем файл\n",
        "!unzip chromedriver-linux64.zip\n",
        "\n",
        "# Проверяем содержимое распакованного архива (чтобы увидеть структуру папок)\n",
        "!ls -l chromedriver-linux64\n",
        "\n",
        "# Перемещаем ChromeDriver в нужную директорию (если папка вложенная)\n",
        "!mv chromedriver-linux64/chromedriver /usr/local/bin/chromedriver\n",
        "\n",
        "!which chromedriver\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "C34SPev0K6t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Перемещаем chromedriver из Google Drive в локальную файловую систему\n",
        "!cp /content/drive/MyDrive/HH_Vacancy/chromedriver /usr/local/bin/chromedriver\n",
        "\n",
        "# Устанавливаем права на выполнение для chromedriver\n",
        "!chmod +x /usr/local/bin/chromedriver\n"
      ],
      "metadata": {
        "id": "eQxoKRfFV65N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "НАЖМИТЕ ЗДЕСЬ ЧТОБ ВВЕСТИ BASE_URL"
      ],
      "metadata": {
        "id": "TKYWOMbjuBRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import logging\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Монтируем Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Настройка логирования\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger()\n",
        "\n",
        "def get_soup_with_retries(url, session, retries=3, delay=5):\n",
        "    \"\"\"\n",
        "    Получить содержимое страницы с повторными попытками.\n",
        "    \"\"\"\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = session.get(url)\n",
        "            if response.status_code == 200:\n",
        "                logger.info(f'Успешно получен контент со страницы {url}')\n",
        "                return BeautifulSoup(response.text, 'html.parser')\n",
        "            else:\n",
        "                logger.error(f'Попытка {attempt + 1} из {retries}. Ошибка: {response.status_code}. Повтор через {delay} секунд.')\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logger.error(f'Попытка {attempt + 1} из {retries}. Исключение: {e}. Повтор через {delay} секунд.')\n",
        "        time.sleep(delay)\n",
        "    logger.error(f'Не удалось получить содержимое с {url} после {retries} попыток.')\n",
        "    return None\n",
        "\n",
        "def save_links_to_file(base_url, file_name, session, start_page=0, end_page=39, single_file=True):\n",
        "    \"\"\"\n",
        "    Сохранить ссылки с вакансий в файл.\n",
        "    \"\"\"\n",
        "    scraped_urls = set()\n",
        "\n",
        "    for page in range(start_page, end_page + 1):\n",
        "        logger.info(f\"Собираем ссылки со страницы {page} на {base_url}...\")\n",
        "        page_url = f'{base_url}&page={page}'\n",
        "        soup = get_soup_with_retries(page_url, session)\n",
        "        if soup:\n",
        "            links = soup.find_all('a', href=True)\n",
        "            for link in links:\n",
        "                href = link['href']\n",
        "                if 'hh.ru/vacancy/' in href:\n",
        "                    scraped_urls.add(href)\n",
        "                    logger.info(f\"Найдена ссылка: {href}\")\n",
        "        else:\n",
        "            logger.warning(f\"Не удалось получить данные со страницы {page} на {base_url}.\")\n",
        "\n",
        "    # Запись результатов в файл\n",
        "    if single_file:\n",
        "        # Проверяем существование файла перед записью\n",
        "        file_path = '/content/drive/MyDrive/HH_Vacancy/hh_vacancies.txt'  # Путь на Google Drive\n",
        "\n",
        "        # Если файл не существует, создаем его\n",
        "        if not os.path.isfile(file_path):\n",
        "            open(file_path, 'w').close()\n",
        "\n",
        "        with open(file_path, 'r+') as file:\n",
        "            existing_links = set(file.read().splitlines())\n",
        "            new_links = scraped_urls - existing_links\n",
        "            file.seek(0, os.SEEK_END)  # Переходим в конец файла для записи новых ссылок\n",
        "            for url in new_links:\n",
        "                file.write(url + '\\n')\n",
        "    else:\n",
        "        # Если нужно записывать в новый файл\n",
        "        with open(file_name, 'w') as file:\n",
        "            for url in scraped_urls:\n",
        "                file.write(url + '\\n')\n",
        "\n",
        "    logger.info(f\"Ссылки с {base_url} успешно сохранены в файл {file_name}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Главная функция для сбора ссылок с HeadHunter.\n",
        "    \"\"\"\n",
        "    # Запрашиваем у пользователя ввод Base_URL\n",
        "    base_url = input(\"Введите Base_URL для сбора вакансий (например, https://hh.ru/search/vacancy?text=python&area=1): \").strip()\n",
        "\n",
        "    if not base_url:\n",
        "        logger.error(\"Base_URL пустой! Убедитесь, что вы ввели корректный URL.\")\n",
        "        return\n",
        "\n",
        "    session = requests.Session()\n",
        "    session.headers.update({\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "    })\n",
        "\n",
        "    file_name = '/content/drive/MyDrive/HH_Vacancy/hh_vacancies.txt'  # Путь к файлу на Google Drive\n",
        "    save_links_to_file(base_url, file_name, session, start_page=0, end_page=10, single_file=True)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Ihr8rCsiRVCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ЗДЕСЬ ПРОИСХОДИТ СБОР ДАННЫХ ДЛЯ EXEL\n"
      ],
      "metadata": {
        "id": "WuTtYKm3ukyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import openpyxl\n",
        "from openpyxl.utils import get_column_letter\n",
        "import threading\n",
        "import queue\n",
        "import random\n",
        "import time\n",
        "import logging\n",
        "import multiprocessing\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "import datetime\n",
        "\n",
        "# Монтируем Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Логирование\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(threadName)s - %(levelname)s - %(message)s')\n",
        "\n",
        "contacts_data = {}\n",
        "\n",
        "# Функция для импорта cookies\n",
        "def import_cookies(driver, url, path_to_cookies):\n",
        "    driver.get(url)\n",
        "    with open(path_to_cookies, 'r') as cookies_file:\n",
        "        cookies = json.load(cookies_file)\n",
        "    for cookie in cookies:\n",
        "        if 'expiry' in cookie:\n",
        "            cookie['expiry'] = int(cookie['expiry'])\n",
        "        if 'sameSite' in cookie and cookie['sameSite'] not in [\"Strict\", \"Lax\", \"None\"]:\n",
        "            cookie['sameSite'] = \"None\"\n",
        "        driver.add_cookie(cookie)\n",
        "    driver.refresh()\n",
        "\n",
        "# Функция для получения контактов\n",
        "def get_contacts(driver, url, xpaths):\n",
        "    driver.get(url)\n",
        "    data = {}\n",
        "    contact_elements = {}\n",
        "\n",
        "    for key, xpath in xpaths.items():\n",
        "        try:\n",
        "            if key == \"Показать контакты\":\n",
        "                show_contacts_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, xpath)))\n",
        "                show_contacts_button.click()\n",
        "\n",
        "                WebDriverWait(driver, 5).until(\n",
        "                    lambda d: all(d.find_elements(By.XPATH, xpaths.get(\"Телефон1\", \"\"))) and\n",
        "                              all(d.find_elements(By.XPATH, xpaths.get(\"Почта1\", \"\"))))\n",
        "\n",
        "                contact_keys = [k for k in xpaths if \"Телефон\" in k or \"Почта\" in k]\n",
        "                for contact_key in contact_keys:\n",
        "                    contact_elements[contact_key] = driver.find_elements(By.XPATH, xpaths[contact_key])\n",
        "\n",
        "            elif \"Телефон\" in key or \"Почта\" in key:\n",
        "                if contact_elements.get(key):\n",
        "                    data[key] = \"; \".join([el.text.strip() for el in contact_elements[key] if el.text.strip()])\n",
        "\n",
        "            elif key == \"Профиль компании\":\n",
        "                company_link_element = WebDriverWait(driver, 10).until(\n",
        "                    EC.presence_of_element_located((By.XPATH, xpath)))\n",
        "                company_url = company_link_element.get_attribute('href')\n",
        "                data[key] = company_url\n",
        "\n",
        "            else:\n",
        "                element = WebDriverWait(driver, 10).until(\n",
        "                    EC.visibility_of_element_located((By.XPATH, xpath)))\n",
        "                if element:\n",
        "                    data[key] = element.text.strip()\n",
        "                else:\n",
        "                    data[key] = \"Не найдено\"\n",
        "\n",
        "        except TimeoutException:\n",
        "            data[key] = \"Не найдено\"\n",
        "            logging.error(f\"Элемент <<{key}>> не найден по XPath: {xpath}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "# Функция для сохранения данных в Excel\n",
        "def save_to_excel(contacts_data , filename):\n",
        "    workbook = openpyxl.Workbook()\n",
        "    sheet = workbook.active\n",
        "    sheet.title = 'HH-Contacts'\n",
        "\n",
        "    if contacts_data:\n",
        "        headers = ['URL'] + list(next(iter(contacts_data.values())).keys())\n",
        "        sheet.append(headers)\n",
        "\n",
        "        for url , data in contacts_data.items():\n",
        "            row = [url]\n",
        "            for key in headers[1:]:\n",
        "                row.append(data.get(key, 'N/A'))\n",
        "            sheet.append(row)\n",
        "\n",
        "        for col_num, column_title in enumerate(headers, 1):\n",
        "            column_width = max(len(column_title), 20)\n",
        "            sheet.column_dimensions[get_column_letter(col_num)].width = column_width\n",
        "\n",
        "        workbook.save(filename)\n",
        "    else:\n",
        "        logging.error(\"Нет данных для сохранения.\")\n",
        "\n",
        "# xpaths_dict, который вы используете для получения данных\n",
        "xpaths_dict = {\n",
        "    'Показать контакты': '//button[@data-qa=\"show-employer-contacts show-employer-contacts_bottom-button\"]',\n",
        "    'Вакансия': '//h1',\n",
        "    'Компания': '//*[@data-qa=\"vacancy-company-name\"]',\n",
        "    'Профиль компании': '//span[@class=\"vacancy-company-name\"]/a',\n",
        "    'Телефон1': '//*[@class=\"bloko-text bloko-text_small\"]/span',\n",
        "    'Телефон2': '//*[@class=\"vacancy-contacts-call-tracking__phone-number\"]',\n",
        "    'Почта1': '//*[@data-qa=\"vacancy-contacts__email\"]',\n",
        "    'Адрес': '//*[@data-qa=\"vacancy-view-raw-address\"]',\n",
        "    'Зарплата': '//*[@data-qa=\"vacancy-salary-compensation-type-net\"]',\n",
        "    'Требуемый опыт': '//*[@data-qa=\"vacancy-experience\"]',\n",
        "    'График': '//*[@data-qa=\"vacancy-view-employment-mode\"]',\n",
        "    'Описание': '//*[@data-qa=\"vacancy-description\"]',\n",
        "    'Навыки': '//*[@data-qa=\"skills-element\"]',\n",
        "}\n",
        "\n",
        "# Функция для повторения с задержкой при обработке каждого URL\n",
        "def retry_with_delay(retry_function, max_retries, retry_delay, *args, **kwargs):\n",
        "    attempt = 0\n",
        "    while attempt < max_retries:\n",
        "        try:\n",
        "            return retry_function(*args, **kwargs)\n",
        "        except Exception as e:\n",
        "            attempt += 1\n",
        "            logging.error(f\"Ошибка при попытке {attempt}: {e}\")\n",
        "            if attempt < max_retries:\n",
        "                time.sleep(retry_delay)\n",
        "    raise Exception(f\"Не удалось выполнить {retry_function.__name__} после {max_retries} попыток\")\n",
        "\n",
        "def worker(path_to_cookies, url_for_auth, user_agents, url_queue, contacts_data_lock, pbar, contacts_data, xpaths_dict, max_retries=3, retry_delay=5, error_urls_queue=None):\n",
        "    user_agent = random.choice(user_agents)\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument(\"--headless\")\n",
        "    chrome_options.add_argument(\"--no-sandbox\")\n",
        "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "    chrome_options.add_argument(\"--disable-gpu\")\n",
        "    chrome_options.add_argument(\"--remote-debugging-port=9222\")\n",
        "    chrome_options.add_argument(f\"user-agent={user_agent}\")\n",
        "\n",
        "    chromedriver_path = \"/usr/local/bin/chromedriver\"  # Указываем локальный путь\n",
        "\n",
        "    chrome_service = Service(chromedriver_path)\n",
        "    local_driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
        "\n",
        "    try:\n",
        "        import_cookies(local_driver, url_for_auth, path_to_cookies)\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                current_url = url_queue.get(block=False)\n",
        "                try:\n",
        "                    # Обработка URL с повторами\n",
        "                    contact_data = retry_with_delay(get_contacts, max_retries, retry_delay, local_driver, current_url, xpaths_dict)\n",
        "                    with contacts_data_lock:\n",
        "                        contacts_data[current_url] = contact_data\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Ошибка при обработке URL {current_url}: {e}\")\n",
        "                    if error_urls_queue is not None:\n",
        "                        error_urls_queue.put(current_url)\n",
        "                finally:\n",
        "                    pbar.update(1)\n",
        "                    logging.info(f\"Processed URL: {current_url}\")\n",
        "                    url_queue.task_done()\n",
        "\n",
        "                    # Задержка между запросами\n",
        "                    sleep_time = random.uniform(5, 10)\n",
        "                    logging.info(f\"Задержка перед следующим запросом: {sleep_time:.2f} сек.\")\n",
        "                    time.sleep(sleep_time)\n",
        "\n",
        "            except queue.Empty:\n",
        "                logging.info(\"Очередь обработана.\")\n",
        "                break\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Неожиданная ошибка: {e}\")\n",
        "    finally:\n",
        "        local_driver.quit()\n",
        "        pbar.update(1)\n",
        "        logging.info(\"WebDriver закрыт и ресурсы очищены.\")\n",
        "\n",
        "\n",
        "# Главная функция скрипта\n",
        "def main():\n",
        "    start_time = time.time()\n",
        "\n",
        "    user_agents = [\n",
        "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36',\n",
        "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15',\n",
        "        'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0',\n",
        "    ]\n",
        "\n",
        "    path_to_cookies = '/content/drive/MyDrive/HH_Vacancy/hh.json'  # Путь к cookies на Google Drive\n",
        "    url_for_auth = 'https://hh.ru/'\n",
        "\n",
        "    contacts_data = {}\n",
        "    contacts_data_lock = threading.Lock()\n",
        "    url_queue = queue.Queue()\n",
        "    error_urls_queue = queue.Queue()\n",
        "\n",
        "    try:\n",
        "        with open('/content/drive/MyDrive/HH_Vacancy/hh_vacancies.txt', 'r') as file:\n",
        "            for url in file:\n",
        "                url = url.strip()\n",
        "                if url:\n",
        "                    url_queue.put(url)\n",
        "    except IOError as e:\n",
        "        logging.error(f\"Ошибка при чтении файла: {e}\")\n",
        "        return\n",
        "\n",
        "    pbar = tqdm(total=url_queue.qsize(), desc=\"Обработка URL\")\n",
        "\n",
        "    num_cores = multiprocessing.cpu_count() or 1\n",
        "    num_threads = min(10, url_queue.qsize(), num_cores)\n",
        "\n",
        "    threads = []\n",
        "    for i in range(num_threads):\n",
        "        thread = threading.Thread(target=worker, args=(path_to_cookies, url_for_auth, user_agents, url_queue, contacts_data_lock, pbar, contacts_data, xpaths_dict, 3, 5, error_urls_queue))\n",
        "        threads.append(thread)\n",
        "        thread.start()\n",
        "\n",
        "    for t in threads:\n",
        "        t.join()\n",
        "\n",
        "    while not error_urls_queue.empty():\n",
        "        url = error_urls_queue.get()\n",
        "        try:\n",
        "            contact_data = retry_with_delay(get_contacts, 3, 5, url, xpaths_dict)\n",
        "            with contacts_data_lock:\n",
        "                contacts_data[url] = contact_data\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Не удалось обработать URL {url} после повторных попыток: {e}\")\n",
        "        pbar.update(1)\n",
        "        logging.info(f\"URL повторно обработан: {url}\")\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    datetime_str = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "    filename = f'/content/drive/MyDrive/HH_Vacancy/hh-vacancies_{datetime_str}.xlsx'\n",
        "    save_to_excel(contacts_data, filename)\n",
        "\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "    print(f\"Сценарий выполнен за {datetime.timedelta(seconds=duration)}\")\n",
        "    logging.info(f\"Сценарий выполнен за {datetime.timedelta(seconds=duration)}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "V0F4-l8xTJ56",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}